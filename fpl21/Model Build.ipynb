{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib as pyplot\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpl21.utils import pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate base data set\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"players_list.json\", \"r\") as f:\n",
    "    print(\"loading players list from file\")\n",
    "    players_list = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Players list file contains player attributes, fixtures list, historical fixtures and previous season performance\n",
    "players_list[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history is previous fictures with stats. fixtures is forward looking\n",
    "print(len(players_list[0]['history']))\n",
    "print(len(players_list[0]['fixtures']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a player teams lookup\n",
    "player_attrs = pd.DataFrame(\n",
    "    [(p['id'], p['web_name'], p['team']) for p in players_list],\n",
    "    columns=['element', 'name', 'team'])\n",
    "#player_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = [p['history'] for p in players_list]\n",
    "df = pd.DataFrame([x for sublist in hist for x in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(player_attrs, on='element')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive version of team diffculty\n",
    "# average points per game\n",
    "team_difficulty = df.groupby('team').total_points.sum() / df.groupby('team').fixture.nunique()\n",
    "team_difficulty.name = 'team_difficulty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team_difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(team_difficulty, left_on='opponent_team', right_index=True) \\\n",
    "       .rename(columns={'team_difficulty': 'opponent_difficulty'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict columns for initial development\n",
    "df = df[\n",
    "    [\n",
    "        'element', 'name', 'fixture', 'team', 'opponent_team',\n",
    "        'was_home', 'opponent_difficulty', 'minutes', 'total_points'\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Others\n",
    "# 'opponent_team', 'kickoff_time', 'team_h_score', 'team_a_score', 'round', 'minutes',\n",
    "# 'goals_scored', 'assists', 'clean_sheets', 'goals_conceded',\n",
    "# 'own_goals', 'penalties_saved', 'penalties_missed', 'yellow_cards',\n",
    "# 'red_cards', 'saves', 'bonus', 'bps', 'influence', 'creativity',\n",
    "# 'threat', 'ict_index', 'value', 'transfers_balance', 'selected',\n",
    "# 'transfers_in', 'transfers_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_points.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature generation\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_avg(df, window, col, default):\n",
    "    rolling = pd.Series(dtype='float64')\n",
    "    for x in df.element.unique():\n",
    "        rolling = rolling.append(df[df.element==x].sort_values('fixture').rolling(window)[col].mean().shift(1))\n",
    "    \n",
    "    # Fill nas with default val\n",
    "    rolling = rolling.fillna(default)\n",
    "    \n",
    "    rolling.name = f\"avg_{col}_L{window}\"\n",
    "    return df.merge(rolling, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 3):\n",
    "    df = rolling_avg(df, i, 'total_points', 0)\n",
    "\n",
    "for i in range(1, 3):\n",
    "    df = rolling_avg(df, i, 'minutes', 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covars = [\n",
    "    #'team', 'opponent_team', # Need to encode these\n",
    "    'was_home', 'opponent_difficulty', 'avg_total_points_L1', 'avg_total_points_L2', 'avg_minutes_L1', 'avg_minutes_L2']\n",
    "\n",
    "X = df[covars]\n",
    "y = df.total_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "train = (X_train, y_train)\n",
    "test = (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(min_samples_split=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(*train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(reg.feature_importances_, index=covars, columns=['importance']) \\\n",
    "    .sort_values('importance').plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train {reg.score(*train)}\")\n",
    "print(f\" Test {reg.score(*test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "| Name | Params | Other | Test Performance |\n",
    "| --- | --- | --- | --- |\n",
    "| Baseline | min_samples_split=100 | | 0.1528 | \n",
    "| | add avg_minutes_L1 L2 | | 0.1693 |\n",
    "\n",
    "\n",
    "| Name | Vars |\n",
    "| --- | --- |\n",
    "| Baseline | 'was_home', 'opponent_difficulty', 'avg_total_points_L1', 'avg_total_points_L2' |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter tuning\n",
    "# results = []\n",
    "# for n in tqdm([2, 5, 10, 20, 50, 100, 200, 500, 1000]):\n",
    "#     reg = RandomForestRegressor(n_estimators=n, min_samples_split=100)\n",
    "#     reg.fit(X_train, y_train)\n",
    "#     results.append((n, reg.score(*train), reg.score(*test)))\n",
    "\n",
    "# pd.DataFrame(results, columns=['ntrees', 'train', 'test']).set_index('ntrees').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_points'] = reg.predict(X[covars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 0.2, len(df)) \n",
    "jitter = df[['total_points', 'predicted_points']]\n",
    "jitter['total_points'] += noise\n",
    "jitter.plot.scatter('total_points', 'predicted_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_points(df, pid):\n",
    "    player = df[df.element==pid]\n",
    "    player.set_index('fixture').sort_index()[['predicted_points', 'total_points']].plot(\n",
    "        kind='bar', ylim=(-5, 25), title=f\"{player.name.iloc[0]} ({pid})\"\n",
    "    )\n",
    "\n",
    "for pid in df.element.unique()[:10]:\n",
    "    plot_predicted_points(df, pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fpl21)",
   "language": "python",
   "name": "fpl21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
